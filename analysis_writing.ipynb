{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "analysis_writing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN3jw416uLlIqax4hYj2Upk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferhaterata/.doom.d/blob/master/analysis_writing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbzIkxMR5Hgp"
      },
      "source": [
        "!pip install z3-solver\n",
        "!pip install angr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1LJrty1-uWk"
      },
      "source": [
        "# Writing Analyses\n",
        "\n",
        "An analysis can be created by subclassing the `angr.Analysis` class.\n",
        "In this section, we'll create a mock analysis to show off the various features.\n",
        "Let's start with something simple:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHDJHOjB8Mqa"
      },
      "source": [
        "import angr\n",
        "\n",
        "class MockAnalysis(angr.Analysis):\n",
        "  def __init__(self, option):\n",
        "    self.option = option\n",
        "\n",
        "angr.AnalysesHub.register_default('MockAnalysis', MockAnalysis) # register the class with angr's global analysis list"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po8n2Dyt-4wx"
      },
      "source": [
        "This is a very simple analysis -- it takes an option, and stores it.\n",
        "Of course, it's not useful, but this is just a demonstration.\n",
        "\n",
        "Let's see how to run our new analysis:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0NppsgY--gf",
        "outputId": "ba33ebb5-7c61-48af-e003-03b2391ff1c8"
      },
      "source": [
        "proj = angr.Project(\"/bin/true\")\n",
        "mock = proj.analyses.MockAnalysis('this is my option')\n",
        "assert mock.option == 'this is my option'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING | 2021-08-27 05:01:47,030 | \u001b[36mcle.loader\u001b[0m | \u001b[36mThe main binary is a position-independent executable. It is being loaded with a base address of 0x400000.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adfPKj7y_3C6"
      },
      "source": [
        "### Working with projects\n",
        "\n",
        "Via some python magic, your analysis will automatically have the project upon which you are running it under the `self.project` property.\n",
        "Use this to interact with your project and analyze it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjnBJU5V_5tu"
      },
      "source": [
        "class ProjectSummary(angr.Analysis):\n",
        "  def __init__(self):\n",
        "    self.result = 'This project is a %s binary with an entry point at %#x.' % (self.project.arch.name, self.project.entry)\n",
        "\n",
        "angr.AnalysesHub.register_default('ProjectSummary', ProjectSummary)\n",
        "proj = angr.Project(\"/bin/true\")\n",
        "\n",
        "summary = proj.analyses.ProjectSummary()\n",
        "print(summary.result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLiOKYVHCD_Q"
      },
      "source": [
        "### Analysis Resilience\n",
        "\n",
        "Sometimes, your (or our) code might suck and analyses might throw exceptions.\n",
        "We understand, and we also understand that oftentimes a partial result is better than nothing.\n",
        "This is specifically true when, for example, running an analysis on all of the functions in a program.\n",
        "Even if some of the functions fails, we still want to know the results of the functions that do not.\n",
        "\n",
        "To facilitate this, the `Analysis` base class provides a resilience context manager under `self._resilience`.\n",
        "Here's an example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmoHa-W3CJYJ"
      },
      "source": [
        "class ComplexFunctionAnalysis(angr.Analysis):\n",
        "  def __init__(self):\n",
        "    self._cfg = self.project.analyses.CFG()\n",
        "    self.results = { }\n",
        "    for addr, func in self._cfg.function_manager.functions.items():\n",
        "      with self._resilience():\n",
        "        if addr % 2 == 0:\n",
        "          raise ValueError(\"can't handle functions at even addresses\")\n",
        "        else:\n",
        "          self.results[addr] = \"GOOD\"\n",
        "\n",
        "angr.AnalysesHub.register_default('ComplexFunctionAnalysis', ComplexFunctionAnalysis)\n",
        "proj = angr.Project(\"/bin/true\")\n",
        "\n",
        "summary = proj.analyses.ComplexFunctionAnalysis()\n",
        "print(summary.results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjGlNKMYCh95"
      },
      "source": [
        "The context manager catches any exceptions thrown and logs them (as a tuple of the exception type, message, and traceback) to `self.errors`.\n",
        "These are also saved and loaded when the analysis is saved and loaded (although the traceback is discarded, as it is not picklable).\n",
        "\n",
        "You can tune the effects of the resilience with two optional keyword parameters to `self._resilience()`.\n",
        "\n",
        "The first is `name`, which affects where the error is logged.\n",
        "By default, errors are placed in `self.errors`, but if `name` is provided, then instead the error is logged to `self.named_errors`, which is a dict mapping `name` to a list of all the errors that were caught under that name.\n",
        "This allows you to easily tell where thrown without examining its traceback.\n",
        "\n",
        "The second argument is `exception`, which should be the type of the exception that `_resilience` should catch.\n",
        "This defaults to `Exception`, which handles (and logs) almost anything that could go wrong.\n",
        "You can also pass a tuple of exception types to this option, in which case all of them will be caught.\n",
        "\n",
        "Using `_resilience` has a few advantages:\n",
        "\n",
        "1. Your exceptions are gracefully logged and easily accessible afterwards. This is really nice for writing testcases.\n",
        "2. When creating your analysis, the user can pass `fail_fast=True`, which transparently disable the resilience, which is really nice for manual testing.\n",
        "3. It's prettier than having `try`/`except` everywhere.\n",
        "\n",
        "Have fun with analyses! Once you master the rest of angr, you can use analyses to understand anything computable!"
      ]
    }
  ]
}